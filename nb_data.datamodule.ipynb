{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "> Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from scp.data.dataset import DataFrameImageDataset, MultiLabelDataFrameImageDataset\n",
    "import pandas as pd\n",
    "\n",
    "class MultiLabelDataFrameDataModule(LightningDataModule):\n",
    "    '''Data module where the underlying dataset is a ´DataFrameImageDataset´. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing image paths, corresponding labels (optional) and \n",
    "        what set the image belongs to (i.e. train, val, test, predict).\n",
    "        \n",
    "    img_col : str\n",
    "        Name of df column containing image paths \n",
    "        \n",
    "    set_col : str\n",
    "        Name of df column containing set designation. \n",
    "        Column must contain one or more of ´train´, ´val´, ´test´ or ´predict´. \n",
    "        \n",
    "    label_col : str; optional\n",
    "        Name of df column containing image labels.\n",
    "        If None, ´self.label_col´ are all zeros. \n",
    "        \n",
    "    root : str; optional\n",
    "        Top-level directory that gets prepended to image paths\n",
    "        \n",
    "    transforms : dict; optional\n",
    "        Dict of composition of albumentation transforms (or any transforms that work on numpy arrays). \n",
    "        Dict keys must be one or more of ´train´, ´val´, ´test´ or ´predict´. \n",
    "        \n",
    "    label_names : list; optional\n",
    "        List of unique label names. Order of list determines what integer a label is mapped to.\n",
    "        If None, ´self.label_names´ are determined by ´self.label´.  \n",
    "        \n",
    "    batch_size : int; optional\n",
    "        Batch size at loading.\n",
    "        \n",
    "    num_workers : int; optional\n",
    "        Number of cpu cores. \n",
    "        \n",
    "    balance_train_ds : bool, optional\n",
    "        If True, the train dataloader samples balanced batches.  \n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_col,\n",
    "        set_col,\n",
    "        label_cols,\n",
    "        root=\"./\",\n",
    "        transforms=dict(),\n",
    "        label_class_names=None,\n",
    "        batch_size=32,\n",
    "        num_workers=1,\n",
    "        balance_train_ds=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.img_col = img_col\n",
    "        self.set_col = set_col\n",
    "        self.label_cols = label_cols\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.label_class_names = label_class_names\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.balance_train_ds = balance_train_ds\n",
    "        \n",
    "        self.setup_called = False\n",
    "\n",
    "    def setup(self, stage=None, ):   \n",
    "        \n",
    "        if self.setup_called:\n",
    "            print(\"Setup has already been called. Set attribute 'setup_called=False' if you want to explicitly reset this.\")\n",
    "        else:\n",
    "            self.setup_called = True\n",
    "            self._train_dss, self.train_dss_names = self._get_datasets(set_name=\"train\")\n",
    "            self._val_dss, self.val_dss_names = self._get_datasets(set_name=\"val\")\n",
    "            self._test_dss, self.test_dss_names = self._get_datasets(set_name=\"test\")\n",
    "            self._predict_dss, self.predict_dss_names = self._get_datasets(set_name=\"predict\")\n",
    "        \n",
    "    def train_dataloader(self, idx=0):\n",
    "        sampler, shuffle = None, True\n",
    "        if self.balance_train_ds:\n",
    "            sampler, shuffle = ImbalancedDatasetSampler, False\n",
    "        dls = self._get_dataloaders(self._train_dss, sampler, shuffle)\n",
    "        if idx != None:\n",
    "            return dls[idx]\n",
    "        return dls\n",
    "\n",
    "    def val_dataloader(self, idx=None):\n",
    "        sampler, shuffle = None, False\n",
    "        dls = self._get_dataloaders(self._val_dss, sampler, shuffle)\n",
    "        if idx != None:\n",
    "            return dls[idx]\n",
    "        return dls\n",
    "    \n",
    "    def test_dataloader(self, idx=None):\n",
    "        sampler, shuffle = None, False\n",
    "        dls = self._get_dataloaders(self._test_dss, sampler, shuffle)\n",
    "        if idx != None:\n",
    "            return dls[idx]\n",
    "        return dls\n",
    "    \n",
    "    def predict_dataloader(self, idx=None):\n",
    "        sampler, shuffle = None, False\n",
    "        dls = self._get_dataloaders(self._predict_dss, sampler, shuffle)\n",
    "        if idx != None:\n",
    "            return dls[idx]\n",
    "        return dls\n",
    "    \n",
    "    def train_dataset(self, idx=0):\n",
    "        if idx != None:\n",
    "            return self._train_dss[idx]\n",
    "        return self._train_dss\n",
    "    \n",
    "    def val_dataset(self, idx=None):\n",
    "        if idx != None:\n",
    "            return self._val_dss[idx]\n",
    "        return self._val_dss\n",
    "    \n",
    "    def test_dataset(self, idx=None):\n",
    "        if idx != None:\n",
    "            return self._test_dss[idx]\n",
    "        return self._test_dss\n",
    "    \n",
    "    def predict_dataset(self, idx=None):\n",
    "        if idx != None:\n",
    "            return self._predict_dss[idx]\n",
    "        return self._predict_dss\n",
    "        \n",
    "    def _get_dataloaders(self, dss, sampler, shuffle):\n",
    "        dls = list()\n",
    "        for ds in dss:\n",
    "            \n",
    "            sampler_instance = None\n",
    "            if sampler:\n",
    "                sampler_instance = sampler(ds)\n",
    "                \n",
    "            dls.append(DataLoader(\n",
    "                dataset=ds,\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=self.num_workers, \n",
    "                sampler=sampler_instance,\n",
    "                shuffle=shuffle\n",
    "            ))\n",
    "            \n",
    "        return dls\n",
    "    \n",
    "    def _get_datasets(self, set_name):\n",
    "        '''Get dataset(s) for a particular set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        set_name : str\n",
    "            Should be one of ´train´, ´val´, ´test´ or ´predict´\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List with at least one ´DataFrameImageDataset´ (which could be empty)\n",
    "        '''\n",
    "        \n",
    "        set_df = self.df[self.df[self.set_col].str.contains(set_name)]\n",
    "        \n",
    "        # get subset dataframe(s) for this particular set\n",
    "        subset_names = list()\n",
    "        subset_dfs = list()\n",
    "        for subset_name, subset_df in set_df.groupby(self.set_col, sort=True):\n",
    "            subset_names.append(subset_name)\n",
    "            subset_dfs.append(subset_df.reset_index(drop=True))\n",
    "        \n",
    "        # in case no subsets where found, add empty df for compatibility\n",
    "        if len(subset_dfs)==0:\n",
    "            subset_names.append(set_name)\n",
    "            subset_dfs.append(pd.DataFrame(columns=set_df.columns))\n",
    "            \n",
    "        # create dataset(s) for this particular set\n",
    "        subset_dss = list()\n",
    "        for subset_df in subset_dfs:\n",
    "            subset_dss.append(MultiLabelDataFrameImageDataset(\n",
    "                df=subset_df,\n",
    "                img_col=self.img_col,\n",
    "                label_cols=self.label_cols,\n",
    "                root=self.root,\n",
    "                img_transform=self.transforms.get(set_name),\n",
    "                label_class_names=self.label_class_names,\n",
    "            ))\n",
    "            \n",
    "        return subset_dss, subset_names\n",
    "    \n",
    "    def update_ds_tfms(self, set_name, idx, tfms):\n",
    "        if set_name==\"train\":\n",
    "            self._train_dss[idx].img_transform = tfms\n",
    "        elif set_name==\"val\":\n",
    "            self._val_dss[idx].img_transform = tfms\n",
    "        elif set_name==\"test\":\n",
    "            self._test_dss[idx].img_transform = tfms\n",
    "        elif set_name==\"predict\":\n",
    "            self._predict_dss[idx].img_transform = tfms\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown set name {set_name}\")\n",
    "\n",
    "class DataFrameDataModule(LightningDataModule):\n",
    "    '''Data module where the underlying dataset is a ´DataFrameImageDataset´. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing image paths, corresponding labels (optional) and \n",
    "        what set the image belongs to (i.e. train, val, test, predict).\n",
    "        \n",
    "    img_col : str\n",
    "        Name of df column containing image paths \n",
    "        \n",
    "    set_col : str\n",
    "        Name of df column containing set designation. \n",
    "        Column must contain one or more of ´train´, ´val´, ´test´ or ´predict´. \n",
    "        \n",
    "    label_col : str; optional\n",
    "        Name of df column containing image labels.\n",
    "        If None, ´self.label_col´ are all zeros. \n",
    "        \n",
    "    root : str; optional\n",
    "        Top-level directory that gets prepended to image paths\n",
    "        \n",
    "    transforms : dict; optional\n",
    "        Dict of composition of albumentation transforms (or any transforms that work on numpy arrays). \n",
    "        Dict keys must be one or more of ´train´, ´val´, ´test´ or ´predict´. \n",
    "        \n",
    "    label_names : list; optional\n",
    "        List of unique label names. Order of list determines what integer a label is mapped to.\n",
    "        If None, ´self.label_names´ are determined by ´self.label´.  \n",
    "        \n",
    "    batch_size : int; optional\n",
    "        Batch size at loading.\n",
    "        \n",
    "    num_workers : int; optional\n",
    "        Number of cpu cores. \n",
    "        \n",
    "    balance_train_ds : bool, optional\n",
    "        If True, the train dataloader samples balanced batches.  \n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        img_col,\n",
    "        set_col,\n",
    "        label_col=None,\n",
    "        root=\"./\",\n",
    "        transforms=dict(),\n",
    "        label_names=None,\n",
    "        batch_size=16,\n",
    "        num_workers=1,\n",
    "        balance_train_ds=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.img_col = img_col\n",
    "        self.set_col = set_col\n",
    "        self.label_col = label_col\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.label_names = label_names\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.balance_train_ds = balance_train_ds\n",
    "        #self.setup()\n",
    "\n",
    "    def setup(self, stage=None):      \n",
    "        self.train_dss = self._get_datasets(set_name=\"train\")\n",
    "        self.val_dss = self._get_datasets(set_name=\"val\")\n",
    "        self.test_dss = self._get_datasets(set_name=\"test\")\n",
    "        self.predict_dss = self._get_datasets(set_name=\"predict\")\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        sampler, shuffle = None, True\n",
    "        if self.balance_train_ds:\n",
    "            sampler, shuffle = ImbalancedDatasetSampler, False\n",
    "        return self._get_dataloaders(self.train_dss, sampler, shuffle)[0] # DO not want to implement multiple dl trainging\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        sampler, shuffle = None, False\n",
    "        return self._get_dataloaders(self.val_dss, sampler, shuffle)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        sampler, shuffle = None, False\n",
    "        return self._get_dataloaders(self.test_dss, sampler, shuffle)[0]\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        sampler, shuffle = None, False\n",
    "        return self._get_dataloaders(self.predict_dss, sampler, shuffle)[0]\n",
    "    \n",
    "    def _get_dataloaders(self, dss, sampler, shuffle):\n",
    "        dls = list()\n",
    "        for ds in dss:\n",
    "            \n",
    "            sampler_instance = None\n",
    "            if sampler:\n",
    "                sampler_instance = sampler(ds)\n",
    "                \n",
    "            dls.append(DataLoader(\n",
    "                dataset=ds,\n",
    "                batch_size=self.batch_size,\n",
    "                num_workers=self.num_workers, \n",
    "                sampler=sampler_instance,\n",
    "                shuffle=shuffle\n",
    "            ))\n",
    "            \n",
    "        return dls\n",
    "    \n",
    "    def _get_datasets(self, set_name):\n",
    "        '''Get dataset(s) for a particular set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        set_name : str\n",
    "            Should be one of ´train´, ´val´, ´test´ or ´predict´\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        List with at least one ´DataFrameImageDataset´ (which could be empty)\n",
    "        '''\n",
    "        \n",
    "        set_df = self.df[self.df[self.set_col].str.contains(set_name)]\n",
    "        \n",
    "        # get subset dataframe(s) for this particular set\n",
    "        subset_dfs = list()\n",
    "        for _, subset_df in set_df.groupby(self.set_col, sort=True):\n",
    "            subset_dfs.append(subset_df.reset_index(drop=True))\n",
    "        \n",
    "        # in case no subsets where found, add empty df for compatibility\n",
    "        if len(subset_dfs)==0:\n",
    "            subset_dfs.append(pd.DataFrame(columns=set_df.columns))\n",
    "            \n",
    "        # create dataset(s) for this particular set\n",
    "        subset_dss = list()\n",
    "        for subset_df in subset_dfs:\n",
    "            subset_dss.append(DataFrameImageDataset(\n",
    "                df=subset_df,\n",
    "                img_col=self.img_col,\n",
    "                label_col=self.label_col,\n",
    "                root=self.root,\n",
    "                img_transform=self.transforms.get(set_name),\n",
    "                label_names=self.label_names,\n",
    "            ))\n",
    "            \n",
    "        return subset_dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
