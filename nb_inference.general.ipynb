{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inference.general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General inference methods\n",
    "\n",
    "> Various general methods to be used during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import BasePredictionWriter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_test_df(df):\n",
    "    '''Converts a df designed for testing to a train/val df as this easier to use for fastai batch inference'''\n",
    "    dummy_train = df.copy()\n",
    "    val = df.copy()\n",
    "    \n",
    "    dummy_train[\"is_valid\"] = False\n",
    "    val[\"is_valid\"] = True\n",
    "    \n",
    "    return val.append(dummy_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PredictionWriter(BasePredictionWriter):\n",
    "    '''Blabla\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    splits : dict; optional\n",
    "        Contains \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, output_dir, output_file, write_interval, splits=None):\n",
    "        super().__init__(write_interval)\n",
    "        self.output_dir = output_dir\n",
    "        self.output_file = output_file\n",
    "        self.splits = splits\n",
    "\n",
    "    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):        \n",
    "        predictions = predictions[0]\n",
    "        probs, gts = zip(*predictions)\n",
    "        probs, gts = torch.concat(probs, dim=0), torch.concat(gts, dim=0)\n",
    "        \n",
    "        preds = (probs, gts)\n",
    "        if self.splits:\n",
    "            preds = self._split_preds(preds)\n",
    "            \n",
    "        torch.save(preds, os.path.join(self.output_dir, f\"{self.output_file}.pt\"))\n",
    "    \n",
    "    def _split_preds(self, preds):\n",
    "        group_names = list(self.splits.keys())\n",
    "        group_sizes = list(self.splits.values())\n",
    "        \n",
    "        probs = torch.split(preds[0], group_sizes)\n",
    "        gts = torch.split(preds[1], group_sizes)\n",
    "\n",
    "        split_preds = dict()\n",
    "        for group_name, prob, gt in zip(group_names, probs, gts):\n",
    "            split_preds[group_name] = (prob, gt)\n",
    "        \n",
    "        return split_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
