{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp projects.self_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-supervised Learning\n",
    "> Self-supervised utility code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from self_supervised.layers import *\n",
    "from self_supervised.models.vision_transformer import *\n",
    "from scp.utils.general import custom_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model splitter functions\n",
    "\n",
    "Split the model architecture at certain points to allow for discriminative learning rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_split1(model):\n",
    "    '''Basic feature extractor & FC head split for '''\n",
    "    groups = L([model.vit_backbone, model.mlp])\n",
    "    return groups.map(params)\n",
    "\n",
    "def model_split2(model):\n",
    "    '''Attempt to do a split like in fastai i.e. feature extractor is split in the middle'''\n",
    "    g1 = nn.Sequential(model.vit_backbone.patch_embed, model.vit_backbone.pos_drop, model.vit_backbone.blocks[:6])\n",
    "    g2 = nn.Sequential(model.vit_backbone.blocks[6:], model.vit_backbone.norm, model.vit_backbone.head)\n",
    "    groups = L([g1, g2, model.mlp])\n",
    "    return groups.map(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://keremturgutlu.github.io/self_supervised/\n",
    "# copy and pasted directly from:\n",
    "# https://github.com/KeremTurgutlu/self_supervised/blob/main/examples/vision/06%20-%20training_dino_iwang.ipynb\n",
    "class ViTClassifier(Module):\n",
    "    def __init__(self, vit_backbone, n_feat_layers, n_classes, lin_f=1024, lin_drop=0.3, pooling='avg'):\n",
    "        self.vit_backbone  = vit_backbone\n",
    "        self.n_feat_layers = n_feat_layers \n",
    "        self.pooling = pooling\n",
    "        out_dim = self.vit_backbone.norm.weight.size(0)\n",
    "        \n",
    "        if self.n_feat_layers == 1: in_f = 2*out_dim\n",
    "        else:\n",
    "            if pooling == 'avg':   in_f = out_dim\n",
    "            elif pooling == 'cat': in_f = out_dim*n_feat_layers\n",
    "        \n",
    "        self.mlp = create_cls_module(in_f, n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.vit_backbone.get_intermediate_layers(x,self.n_feat_layers)\n",
    "        \n",
    "        if self.n_feat_layers == 1:\n",
    "            # cat [CLS] token and avgpooled output tokens from the last layer\n",
    "            cls_token, output_tokens = out[0][:,0],out[0][:,1:]\n",
    "            x = torch.cat([cls_token, output_tokens.mean(1)], dim=1)\n",
    "        else:\n",
    "            # avgpool or cat [CLS] tokens from last n layers\n",
    "            out = [o[:,0] for o in out] \n",
    "            if self.pooling == 'avg':   x = torch.stack(out,dim=0).mean(0)\n",
    "            elif self.pooling == 'cat': x = torch.cat(out, 1)\n",
    "            else:                       raise Exception(\"Pooling should be avg or cat\")\n",
    "                \n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_state_dict(arch, pretraining, state_dict_path:str=None, **kwargs):\n",
    "    '''Get pretrained arch'''\n",
    "    if arch == \"resnet50\":\n",
    "        if pretraining == \"sl-imagenet\":\n",
    "            return resnet50(pretrained=True).state_dict()\n",
    "        elif pretraining == \"dino-imagenet\":\n",
    "            # https://github.com/facebookresearch/dino\n",
    "            return torch.hub.load('facebookresearch/dino:main', 'dino_resnet50').state_dict()\n",
    "        elif pretraining == \"dino-custom\":\n",
    "            dino_state_dict = custom_load(state_dict_path, **kwargs)\n",
    "            state_dict = OrderedDict()\n",
    "            for k,v in dino_state_dict.items():\n",
    "                if \"teacher\" not in k and k!=\"C\":\n",
    "                    state_dict[k] = v\n",
    "            return state_dict\n",
    "        else:\n",
    "            raise Exception(f\"Unknown pretraining '{arch}'\")\n",
    "            \n",
    "    elif arch == \"deit_small\":\n",
    "        if pretraining == \"sl-imagenet\":\n",
    "            # https://github.com/facebookresearch/deit\n",
    "            return torch.hub.load('facebookresearch/deit:main', 'deit_small_patch16_224', pretrained=True).state_dict()\n",
    "        elif pretraining == \"dino-imagenet\":\n",
    "            # https://github.com/facebookresearch/dino\n",
    "            return torch.hub.load('facebookresearch/dino:main', 'dino_vits16').state_dict()\n",
    "        elif pretraining == \"dino-custom\":\n",
    "            dino_state_dict = custom_load(state_dict_path, **kwargs)\n",
    "            state_dict = OrderedDict()\n",
    "            for k,v in dino_state_dict.items():\n",
    "                if \"teacher\" not in k and k!=\"C\":\n",
    "                    state_dict[k] = v\n",
    "            return state_dict\n",
    "        else:\n",
    "            raise Exception(f\"Unknown pretraining '{arch}'\")\n",
    "            \n",
    "    else:\n",
    "        raise Exception(f\"Unknown architecture '{arch}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dino_arch(arch:str, **kwargs):\n",
    "    '''We do not care about weights here, simply get the model architecture'''\n",
    "\n",
    "    if arch == \"deit_small\": # 21M params\n",
    "        model = deit_small(**kwargs) # naming artefact (dino fastai library and dino FB library)\n",
    "    elif arch == \"resnet50\":\n",
    "        model = resnet50()\n",
    "        model.embed_dim = model.fc.weight.shape[1]\n",
    "        model.fc = Identity()\n",
    "    else:\n",
    "        raise Exception(f\"Unknown architecture '{arch}'\")\n",
    "        \n",
    "    return MultiCropWrapper(model)\n",
    "\n",
    "def get_opt_func(optimizer:str):\n",
    "    '''get optimizer'''\n",
    "    if optimizer==\"adam\":\n",
    "        return Adam\n",
    "    elif optimizer==\"sgd\":\n",
    "        return SGD\n",
    "    else:\n",
    "        raise Exception(f\"No optimizer found that matches '{optimizer}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
