{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils.general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General utility functions\n",
    "\n",
    "> Various methods to modify and work with python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import yaml\n",
    "import os\n",
    "import torchvision\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from fastai.vision.all import *\n",
    "import gc\n",
    "import torch\n",
    "from zipfile import ZipFile\n",
    "from os.path import basename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def load_config_yaml(path_to_yaml):\n",
    "    '''Load project config yaml and change relative paths to absolute paths'''\n",
    "    \n",
    "    with open(path_to_yaml) as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "    parent_dir = Path(os.path.dirname(os.getcwd()))\n",
    "    for k, v in config.items():\n",
    "        if \"path\" in k:\n",
    "            config[k] = parent_dir/v\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "p2t = torchvision.transforms.ToTensor()\n",
    "t2p = torchvision.transforms.ToPILImage()\n",
    "a2p = PIL.Image.fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AggregatingHook(Hook):\n",
    "    '''aggregate hook outputs in 'stored' in case inference is carried out over the entire dataset in a loop'''\n",
    "    def __init__(self, m, hook_func, is_forward=True, detach=True, cpu=False, gather=False):\n",
    "        super().__init__(m, hook_func, is_forward, detach, cpu, gather)\n",
    "        self.stored = list()\n",
    "        \n",
    "    def hook_fn(self, module, input, output):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input,output = to_detach(input, cpu=self.cpu, gather=self.gather),to_detach(output, cpu=self.cpu, gather=self.gather)\n",
    "        self.stored.append(self.hook_func(module, input, output))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def n_argmin(arr:np.array, n:int):\n",
    "    '''returns the indices of the n-smallest values. Note that these may not be in sorted order!'''\n",
    "    return np.argpartition(arr, n)[:, :n] \n",
    "    \n",
    "def n_argmax(arr:np.array, n:int):\n",
    "    '''returns the indices of the n-largest  values. Note that these may not be in sorted order!'''\n",
    "    return np.argpartition(arr, -n)[:, -n:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def state_dicts_equal(state_dict1:dict, state_dict2:dict, verbose:bool=False):\n",
    "    '''Check if two state dicts are the same with a margin of error\n",
    "    \n",
    "    Do not need to have the same key names but need same number of keys\n",
    "    '''\n",
    "    \n",
    "    equal = True\n",
    "    \n",
    "    # check if state dicts have same length\n",
    "    if len(state_dict1) != len(state_dict2):\n",
    "        equal = False\n",
    "        error_msg = f\"Length mismatch of {len(state_dict1)} and {len(state_dict2)}\"\n",
    "    \n",
    "    # check if state dicts have same shape and content\n",
    "    for (k1, v1), (k2, v2) in zip(state_dict1.items(), state_dict2.items()):\n",
    "        if not torch.allclose(v1, v2):\n",
    "            equal = False\n",
    "            if v1.shape != v2.shape:\n",
    "                error_msg = f\"Shape mismatch for keys '{k1}' ({v1.shape}) and '{k2}' ({v2.shape})\"\n",
    "            else:\n",
    "                error_msg = f\"Content mismatch for keys '{k1}' and '{k2}'\"\n",
    "    \n",
    "    # show errors if applicable\n",
    "    if verbose and not equal:\n",
    "        print(error_msg)\n",
    "        \n",
    "    return equal\n",
    "\n",
    "def convert_state_dict(state_dict1:dict, state_dict2:dict, strict:bool=True, verbose:bool=False):\n",
    "    '''Using keys from 1 and values from 2\n",
    "    \n",
    "    Will return a state dict that has min number of keys min(state_dict1, state_dict2).\n",
    "    '''\n",
    "    \n",
    "    state_dict = OrderedDict()\n",
    "    count = 0\n",
    "    \n",
    "    for (k1, v1), (k2, v2) in zip(state_dict1.items(), state_dict2.items()):\n",
    "        \n",
    "        # if strict is True we only want layers that match each other's shape\n",
    "        if strict:\n",
    "            if v1.shape==v2.shape:\n",
    "                state_dict[k1] = v2\n",
    "            else:\n",
    "                count += 1\n",
    "        # if strict is False we simply fuse the keys and values from dict1 and dict2 respectively\n",
    "        else:\n",
    "            state_dict[k1] = v2\n",
    "            \n",
    "    if verbose:\n",
    "        print(f\"New state dict has  {len(state_dict)} layers based on previous {len(state_dict1)} and {len(state_dict2)} layers\")\n",
    "        if strict:\n",
    "            print(f\"Ignored {count} layers due to shape mismatch\")\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def custom_save(obj, path, final_run:bool=False):\n",
    "    \n",
    "    tag = \"\"\n",
    "    if final_run:\n",
    "        tag = \"_final\"\n",
    "        \n",
    "    torch.save(obj, f\"{path}{tag}.pkl\")\n",
    "   \n",
    "def custom_load(path, final_run:bool=False, **kwargs):\n",
    "    \n",
    "    tag = \"\"\n",
    "    if final_run:\n",
    "        tag = \"_final\"\n",
    "        \n",
    "    return torch.load(f\"{path}{tag}.pkl\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def zip_dir(dir_in, dir_out):\n",
    "    # create a ZipFile object\n",
    "    with ZipFile(dir_out, 'w') as zipObj:\n",
    "        # Iterate over all the files in directory\n",
    "        for foldername, subfolders, filenames in os.walk(dir_in):\n",
    "            for filename in filenames:\n",
    "                # create complete filepath of file in directory\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "                # Add file to zip\n",
    "                zipObj.write(file_path, basename(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def isnotebook():\n",
    "    '''Check if python code is run from a jupyter notebook or not'''\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
